\documentclass[aspectratio=43]{beamer}
% Theme works only with a 4:3 aspect ratio
\usetheme{CSCS}

\usepackage{tikz}

\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usetikzlibrary{pgfplots.groupplots,spy,patterns}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{positioning}
\usepackage{listings}
\usepackage{color}
\usepackage{dirtree}
\usepackage{tcolorbox}
\usepackage{anyfontsize}
\usepackage{xspace}
\usepackage{graphicx}
\usepackage{pifont}

% define footer text
\newcommand{\footlinetext}{Alps User Environments}

% Select the image for the title page
\newcommand{\picturetitle}{slide-images/image5.pdf}

% fonts for maths
\usefonttheme{professionalfonts}
%\usefonttheme{serif}

\input{listing-spec.tex}

% source code listing
\newcommand\TS{\rule{0pt}{2.6ex}}       % Top strut
\newcommand\BS{\rule[-1.2ex]{0pt}{0pt}} % Bottom strut
\newcommand{\hl}[1]{\textbf{\textcolor{blue}{#1}}} % for hilighting optimal entries in tables
\newcommand{\rl}[1]{\textbf{\textcolor{red}{#1}}} % for hilighting sub-optimal entries in tables
\newcommand{\img}[1]{{\Large \textbf{IMAGE {#1}}}}
\newcommand{\hilight}[1]{\textcolor{blue!20!orange}{#1}}
\newcommand{\alps}[0]{Alps\xspace}
\newcommand{\stackinator}[0]{Stackinator\xspace}
\newcommand{\stackboxwidth}[0]{5cm}
\newcommand{\stackboxheight}[0]{1cm}
\newcommand{\stacksystemcolor}[0]{blue!10}
\newcommand{\stackbootstrapcolor}[0]{green!10}
\newcommand{\stackcolor}[0]{orange!10}

% set indent to a more reasonable level (so that itemize can be used in columns)
\setlength{\leftmargini}{20pt}

\DeclareTextFontCommand{\emph}{\color{blue!85!black}}

\author{
    \textbf{B.~Cumming},
    J.~Coles,
    T-I.~Manitaras,
    J-G.~Piccinali,
    S.~Pintarelli,
    H.~Stoppels}
\title{\centering Deploying Alternative User Environments on Alps}
\subtitle{CUG23 -- Helsinki}

\begin{document}

\setlength\labelsep   {\dimexpr\labelsep - 0.2em\relax}
\setlength\leftmargini{\dimexpr\leftmargini - 1.0em\relax}

% TITLE SLIDE
\cscstitle

%-------------------------------------------
\begin{frame}[fragile]{}
    \vspace{-60pt}
    \begin{center}
    \includegraphics[width=\textwidth]{images/alps.png}

    Alps is the new HPE Cray EX-based infrastructure at CSCS.

    \vspace{15pt}

        Consolidate separate service-specific clusters onto a single infrastructure -- versatile software-defined clusters (\emph{vClusters}) with workload-specific software environment, scheduler, storage and network isolation.

    \vspace{15pt}

    \dots software stack deployment won't scale with our existing deployment model\dots

    \end{center}

\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{Monolithic Software Stacks}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \includegraphics[width=\textwidth]{images/stack-old.png}
        \end{column}
        \begin{column}{0.5\textwidth}

            \small

            Sites provide CPE -- then provide software built on top:
            % point out presentations past and present
            \begin{itemize}
                \item install \emph{all the software for all the users} on a shared file system;
                \item use CPE modules + site modules for environment customisation.
            \end{itemize}

            CPE presents challenges as a software stack foundation:
            \begin{itemize}
                \item changes every 3 months 
                \item has a large surface area of possible bugs and regressions.
                \item deploying fixes takes minimum 3-6 months.
            \end{itemize}
        \end{column}
    \end{columns}
\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{Bespoke SW stacks}
    \begin{columns}[T]
        \begin{column}{0.6\textwidth}
            Start with a simpler foundation:
            \begin{itemize}
                \item CrayOS + libfabric + Slurm;
                \item no CPE;
                \item less frequent changes over a smaller area.
            \end{itemize}

            Provide workflow-specific software stacks:
            \begin{itemize}
                \item only the packages that are needed;
                \item deployed independently;
                \item built using Spack.
            \end{itemize}

            \begin{center}
            \emph{``You can create environments without modules using Spack. ''}\\
            \emph{``It is tricky to configure Spack. ''}
            \end{center}


        \end{column}
        \begin{column}{0.5\textwidth}
            \includegraphics[width=\textwidth]{images/stack-new.png}
        \end{column}
    \end{columns}
\end{frame}
%-------------------------------------------

\cscschapter{The Stackinator: Building Environments}

%-------------------------------------------
\begin{frame}[fragile]{Stackinator is Opinionated}
    \begin{center}
        Self contained software stacks are built through a workflow codified in a tool CSCS developed \emph{Stackinator}.

    \vspace{10pt}

        \textbf{provide the inputs}: \emph{YAML recipe} and \emph{system configuration} \dots

    \vspace{10pt}

        \textbf{perform the steps}: \emph{stack-config} then \emph{make} \dots

    \vspace{10pt}

        \dots to build a software stack following the best-practices and HPE Cray EX-specific methods developed by CSCS (Harmen Stoppels).

    \vspace{10pt}

        \emph{Each stack exposes a spack upstream interface, and optional modules and environment views.}

    \end{center}

    \url{https://github.com/eth-cscs/stackinator}
\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{Stackinator}
    Stackinator provides a CLI tool to configure the software stack on the target system:

            \begin{lstlisting}[style=talkbash]
> stack-config --recipe $recipe_path \
    --system $CLUSTERNAME --build /dev/shm/build
> cd /dev/shm/build
> env --ignore-environment PATH=/usr/bin:/bin:`pwd`/spack/bin make store.squashfs -j64
            \end{lstlisting}

    \begin{itemize}
        \item \emph{recipe}: YAML files that describe compilers, software packages, and tests for software stack.
        \item \emph{system}: System config for few libraries (gcc, libfabric, xpmem, slurm, rdma-core).
        \item \emph{mount}: The installation path (in the recipe).
        \item \emph{build}: Where the build will be performed.
    \end{itemize}
\end{frame}

%-------------------------------------------
\begin{frame}[fragile]{Stacks}
    A ``Spack Stack'' is built in layers on top of a handful of external system dependencies.
    \begin{center}
        \input{images/stack.tex}
    \end{center}
\end{frame}
%-------------------------------------------


%-------------------------------------------
\begin{frame}[fragile]{System Configurations}
    A Spack configuration for the target vCluster that describes the handful of system dependencies.

    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
        \begin{codecolumn}{compilers.yaml}
            \begin{lstlisting}[style=talkyaml]
compilers:
- compiler:
 spec: gcc@7.5.0
  paths:
   cc: /usr/bin/gcc
   cxx: /usr/bin/g++
   f77: /usr/bin/gfortran
   fc: /usr/bin/gfortran
  flags: {}
  operating_system: sles15
  target: x86_64
            \end{lstlisting}
        \end{codecolumn}
        \end{column}
        \begin{column}{0.5\textwidth}
        \begin{codecolumn}{packages.yaml}
            \begin{lstlisting}[style=talkyaml]
packages:
 libfabric:
  buildable: false
  externals:
  - spec: libfabric@1.15.2.0
    prefix: /opt/cray/libfabric/1.15.2.0/
 slurm:
  buildable: false
  externals:
  - spec: slurm@22-5-2
    prefix: /usr
 xpmem: ...
 rdma-core: ...
            \end{lstlisting}
        \end{codecolumn}
        \end{column}
    \end{columns}
\end{frame}

%-------------------------------------------
\begin{frame}[fragile]{Recipe: general configuration}

Name, mount point, the version of Spack to use and mirror configuration.

\begin{code}{\lstinline{config.yaml}}
\lstinputlisting[style=talkyaml]{src/nv-recipe/config.yaml}
\end{code}

\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{Recipe: compiler toolchains}

Compilers are built in three stages
\begin{enumerate}
\item \emph{bootstrap}: gcc built using the system compiler (gcc 7.5.0).
%    * `gcc:specs`: single spec of the form `gcc@version`.
%    * no Fortran, not optimised
%    * The selected version should have full support for the target architecture in order to build optimised gcc toolchains in step 2.
%    * tabes 2.5 minutes to build
\item \emph{gcc}: Optimised gcc version(s) provided by the stack.
%    * `gcc:specs`: A list of _at least one_ of the specs of the form `gcc@version`.
%    * includes Fortran, tuned.
%    * takes 25 minutes to build
\item \emph{llvm}: (optional) nvhpc and/or llvm toolchains buil with gcc from step 2.
%    * `llvm:specs`: a list of specs of the form `nvhpc@version` or `llvm@version`.
%    * `llvm:requires`: the version of gcc from step 2 that is used to build the llvm compilers.
\end{enumerate}


\begin{code}{\lstinline{compilers.yaml}}
\lstinputlisting[style=talkyaml]{src/nv-recipe/compilers-annotated.yaml}
\end{code}

\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{Recipe: environments}

    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
        \begin{codecolumn}{environments.yaml}
\lstinputlisting[style=talkyaml, firstline=1, lastline=16]{src/nv-recipe/environments.yaml}
        \end{codecolumn}
        \end{column}
        \begin{column}{0.5\textwidth}
        \begin{codecolumnnotitle}{}
\lstinputlisting[style=talkyaml, firstline=17]{src/nv-recipe/environments.yaml}
        \end{codecolumnnotitle}
        \end{column}
    \end{columns}

\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{Building}
    \begin{columns}[T]
        \begin{column}{0.6\textwidth}
            stack-config generates a build path with a hierarchy of Makefiles that build the stack as a DAG of Spack environments.
            \begin{itemize}
                \item build path is in /dev/shm -- build in memory
                \item Bubblewrap (bwrap) is used to mount the \emph{store} path at the destination during builds
            \end{itemize}
            %\begin{center}
                \hspace{1.5cm}\input{images/env-dag-small.tex}
            %\end{center}
        \end{column}


        \begin{column}{0.4\textwidth}
            {
            \setlength{\DTbaselineskip}{5pt}
            \footnotesize
            \input{src/build-path.tex}
            }
        \end{column}
    \end{columns}
\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{Wait! What about MPI?}
    \begin{columns}[T]
        \begin{column}{0.65\textwidth}
            Cray-mpich is the only robust MPI for SS11 as of May 2023.
            \begin{itemize}
                \item We used OpenMPI+ucx on SS10
            \end{itemize}
                % (early version of the stack used OpenMPI on SS10)
                % (OpenMPI and MPICH would be very welcome)

            \vspace{10pt}

            Stackinator uses a custom Spack package for cray-mpich:
            \begin{itemize}
                \item Repackage headers, libs, compiler wrappers from RPMs.
                \item Store as tar-balls CSCS-private artifactory.
                \item Run patchelf on libraries and string-substitution on compiler wrappers.
            \end{itemize}
            \emph{It takes an engineer an hour to create the binary package for each new CPE release.}
        \end{column}
        \hspace{-40pt}
        \begin{column}{0.4\textwidth}
            {
            \setlength{\DTbaselineskip}{5pt}
            \footnotesize
            \input{src/cray-mpich-tree-short.txt}
            }
        \end{column}
    \end{columns}

\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{MPI Configuration is Opinionated}

\begin{code}{environments.yaml: "The user requests cray-mpich"}
    \begin{lstlisting}[style=talkyaml]
myenv:
    compiler:
    - toolchain: gcc
      spec: gcc@11
    mpi:
      spec: cray-mpich@8.1.18.4
      gpu: cuda \end{lstlisting}
\end{code}

\begin{code}{Generated Spack specs in spack.yaml}
    \begin{lstlisting}[style=talkyaml]
# cray-mpich specs are "simple"
specs:
- cray-mpich@8.1.18.4 +cuda

# The tool can generate more complex specs, e.g. OpenMPI on SS10:
specs:
- openmpi@4.0:4 +cuda +cxx +pmi schedulers=slurm fabrics=ucx
- ucx +rdmacm +cma +verbs +xpmem +ib_hw_tm +mlx5_dv +dc +ud +rc +dm +optimizations +gdrcopy ~assertions ~debug \end{lstlisting}
\end{code}

\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{Spack package}

\begin{code}{repo/packages/cray-mpich/package.py}
    \begin{lstlisting}[style=talkbash]
@run_after("install")
def fixup_binaries(self):
  for root, _, files in os.walk(self.prefix):
    for f in [os.path.join(root, name) for name in files]
      if not self.should_patch(f): continue
      patchelf("--force-rpath", "--set-rpath", rpath, f)
      if "libmpi_gtl_cuda.so" in str(f):
        patchelf("--add-needed", "libstdc++.so", f)

@run_after("install")
def fixup_compiler_paths(self):
  filter("@@CC@@", self.compiler.cc,self.prefix.bin.mpicc)
  filter("@@PREFIX@@", self.prefix, self.prefix.bin.mpicc)
  if   "+cuda" in self.spec:gtl_library = "-lmpi_gtl_cuda"
  elif "+rocm" in self.spec:gtl_library = "-lmpi_gtl_hsa"
  else:                     gtl_library = ""
  filter("@@GTL@@", gtl_library, self.prefix.bin.mpicc) \end{lstlisting}
\end{code}

\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{Optimising Build Times}
    Building stacks is resource intensive: 30~min -- 3~hours with 64-cores.

    \vspace{10pt}

    Build times are the main pain point for developers.

    \vspace{10pt}

    \begin{itemize}
        \item \emph{Parallelise the build}: build Spack environments in parallel
        \begin{itemize}
            \item Expose every opportunity to build packages concurrently.
        \end{itemize}
        \item \emph{Build in memory}:
        \begin{itemize}
            \item Build in /dev/shm.
            \item Use Bubblewrap (bwrap) to bind to the target installation path.
        \end{itemize}
        \item \emph{Cache previous builds}:
        \begin{itemize}
            \item Only build packages once.
            \item Use Spack binary build caches.
        \end{itemize}
    \end{itemize}
\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{Optimising Build Times}
    \begin{center}
        \input{images/image-build.tex}
    \end{center}
\end{frame}
%-------------------------------------------


\cscschapter{Deploying spack-stacks}

%-------------------------------------------
\begin{frame}[fragile]{SquashFS}
    The software stack can be copied to a shared file system once built.

    \vspace{20pt}

    At CSCS they are deployed as SquashFS images:
    \begin{itemize}
        \item consistent performance -- always faster than a shared file system;
        \item reduced storage requirements -- compression and deduplication.
        \item each stack is a single binary artifact -- easy to version, roll back and manage in CI/CD pipelines.
    \end{itemize}

    \vspace{20pt}

    \begin{center}
    \emph{SquashFS requires some additional tooling...}
    \end{center}
\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{CLI Utilities}
    Non-privileged users are able to mount SquashFS images at runtime using the \emph{squashfs-mount} CLI setuid utility that:
    \begin{enumerate}
    \item creates a new mount namespace;
    \item mounts the SquashFS file through \emph{libmount};
    \item then drops privileges and executes a given command.
    \end{enumerate}

    \begin{code}{mounting a squashfs image}
\lstinputlisting[style=talkyaml]{src/squashfs-mount.sh}
    \end{code}

    \begin{center}
        \textbf{The image is mounted in the new process -- processes (users) on the same node can mount different images.}
    \end{center}

    \vspace{10pt}

    Open Source on GitHub with RPMs for Cray EX.\\\url{https://github.com/eth-cscs/squashfs-mount}
\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{CLI Utilities}
    A CLI tool \emph{uenv} is under development.
    \begin{enumerate}
    \item for listing, starting, stopping user-environments
    \end{enumerate}

    \begin{code}{mounting a squashfs image}
\lstinputlisting[style=talkyaml]{src/uenv.sh}
    \end{code}

    \vspace{10pt}

    Open Source on GitHub.\\\url{https://github.com/eth-cscs/uenv}
\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{SLURM}
    A Slurm plugin manages mounting environmnents on compute nodes.
    \begin{code}{Launch with explicit flags}
            \begin{lstlisting}[style=talkbash]
% srun --uenv-mount=/user-environment \
       --uenv-file=img.squashfs \
       -n2 -N2 osu_bw
            \end{lstlisting}
    \end{code}
    \begin{code}{Inherit the environment from the login node}
            \begin{lstlisting}[style=talkbash]
% squashfs-mount img.squashfs /user-environment bash
% srun -n2 -N2 osu_bw
            \end{lstlisting}
    \end{code}

    Also works intuitively for \emph{sbatch} -- user can set a default image that, and individual \emph{srun} in the script can use different environments.

    Open Source on GitHub with RPMs for Cray EX.\\\url{https://github.com/eth-cscs/slurm-uenv-mount/}
\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{CI/CD}
    \begin{center}
    CI/CD pipelines \emph{from recipe to deployed SquashFS image} is a work in progress.
    \end{center}

    \vspace{10pt}

    Recipes are stored in a GitHub repository -- Pull requests and merges trigger a pipeline:
    \begin{enumerate}
        \item \emph{\sc Build Stage}: launch a Slurm job on the target cluster+architecture that uses stackinator to configure then build the image.
        \item push the generated image to a JFrog artifactory
        \item \emph{\sc Test Stage}: pull the image and run a Slurm job that executes ReFrame tests.
        \item post status to GitHub
        \item \emph{\sc Deploy Stage}: promote artifact to deployment artifactory (manual).
    \end{enumerate}

    \url{https://github.com/eth-cscs/alps-spack-stacks}
\end{frame}
%-------------------------------------------

\cscschapter{Results}

%-------------------------------------------
\begin{frame}[fragile]{OSU}
    We run OSU benchmarks compiled using CPE and Spack Stacks to understand the effect of packaging cray-mpich outside CPE.
\begin{center}
    \begin{tabular}{l |c  c }
                      & CPE   & Spack Stack \\
          \hline
        osu-benchmark & 5.9   & 5.9       \\
        cray-mpich    & 8.1.21& 8.1.24    \\
        gcc           & 11.2  & 11.3      \\
        cuda          & 11.6  & 11.8      \\
    \end{tabular}
\end{center}

    The benchmarks are run on \emph{Clariden}, a vCluster with \emph{64-core EPYC CPU} and  \emph{4 A100 GPUs} -- similar to Perlmutter.

\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{OSU - P2P Bandwidth}
    \begin{center}
        \input{images/osu-p2p-bw-slides.tex}
    \end{center}
\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{OSU - P2P Latency}
    \begin{center}
        \input{images/osu-p2p-lat-slides.tex}
    \end{center}
\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{GROMACS}
    A GROMACS strong scaling benchmarks: a 1.4-million atom system (a pair of hEGFR Dimers of 1IVO and 1NQL) from the HECBioSim benchmarks suite.
\begin{center}
    \begin{tabular}{|l |c  c| }
        \cline{2-3}
\multicolumn{1}{c|}{} & CPE   & Spack Stack \\
        \hline
        gromacs       & 2021.5   & 2021.5   \\
        fftw          & 3.3.10   & 3.3.10   \\
        openblas      & 0.3.21   & 0.3.21   \\
        cray-mpich    & 8.1.21   & 8.1.24   \\
        gcc           & 11.2     & 11.3     \\
          \hline
    \end{tabular}
\end{center}

    Run on \emph{Clariden}, a vCluster with \emph{64-core EPYC CPU} and  \emph{4 Mi250x GPUs} -- identical to LUMI/Frontier/Setonix.
\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{GROMACS - Strong Scaling}
    A difference of maximum $\pm$1.5\% between the CPE and the Spack-stack.
    \begin{center}
        \input{images/gromacs-slides.tex}
    \end{center}
\end{frame}
%-------------------------------------------

\cscschapter{Wrapping up}

%-------------------------------------------
\begin{frame}[fragile]{An opinionated appeal}
    \begin{center}
    Integration of other CPE products -- libsci, cce, etc -- would be great.

    \vspace{20pt}

    Spack support is simple:

    \vspace{20pt}

    \emph{CPE packages can be installed individually without environment variables or modules, like normal software}.

    \vspace{20pt}

    \emph{In an ideal world we could build cray-mpich and libfabric+CXI from source}.
    \end{center}
\end{frame}
%-------------------------------------------

\cscschapter{Thank you}

\cscschapter{Backup}

%-------------------------------------------
\begin{frame}[fragile]{DDT}
    \begin{center}
        \includegraphics[width=\textwidth]{images/sph-ddt-uenv.png}
    \end{center}
\end{frame}

%-------------------------------------------
\begin{frame}[fragile]{Configuration of mpicc}
\begin{code}{bin/mpicc}
    \begin{lstlisting}[style=talkbash]
prefix="/user-environment/linux-sles15-zen3/gcc-11.3.0/cray-mpich-8.1.18.4-gcc-... long hash ..."
CC="${prefix}/bin/gcc"
$CC ${final_cppflags} ${final_cflags} ${final_ldflags} "${allargs[@]}" -I$includedir -L$libdir -Wl,-rpath,$libdir -lmpi -lmpi_gtl_cuda ${final_libs} \end{lstlisting}
\end{code}

\end{frame}
%-------------------------------------------

%-------------------------------------------
\begin{frame}[fragile]{Objectives}
    We have the following objectives for our software stacks:
    \begin{itemize}
        \item Reproducable from simple recipes:
        \begin{itemize}
            \item versionable with git;
            \item descriptive: what not how.
        \end{itemize}
        \item Separate system-specific configuration from recipe, so that the recipe does not need modification to
        \begin{itemize}
            \item rebuild when a system is updated.
            \item build for different systems.
        \end{itemize}
        %\item Easy roll back.
        %\item Testable.
    \end{itemize}
\end{frame}
%-------------------------------------------


\end{document}
